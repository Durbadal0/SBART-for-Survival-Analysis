for(i in 1:n){
left[i]    = ifelse(M[i]>0, t[i]*(runif(1))^(1/M[i]), t[i])
right[i]   = t[i] + rexp(1)
}
train_data  = data.frame(cbind(left, right, X, cluster, event=array(1,n)))
colnames(train_data) = c("left", "right", "x1", "x2", "x3", "x4", "x5", "id", "event")
return(list(X=X, t = t, left = left, right = right, cluster = cluster , rand_effects = rand_effects,
k=k, lambda=lambda, train_data = train_data, p=p))
}
my_data        = sim_data()
train_data     = my_data$train_data
p              = my_data$p
n              = nrow(train_data)
num_cluster    = my_data$k             #no of clusters
rand_effects   = my_data$rand_effects
lambda         = my_data$lambda
left           = train_data$left
right          = train_data$right
max            = max(left,right)
left           = left/max
right          = right/max
X              = cbind(train_data$x1, train_data$x2, train_data$x3, train_data$x4, train_data$x5)
cluster        = train_data$id
# Test dataset =================================================================================
test = function(n=100, p=5, k=10, cl_size = n/k){
rand_effects = runif(k,0,0.2)
cluster      = c(rep(1:k, cl_size))
X            = matrix(runif(n*p), nrow = n, byrow = TRUE)
lambda       = 10*sin(pi*X[,1]*X[,2]) + 20*(X[,3]-0.5)**2 + 10*X[,4] + 5*X[,5]
t            = array(NA, n)
for(i in 1:n){
t[i] = rgamma(1, shape=lambda[i]+rand_effects[cluster[i]], rate=6)
}
test_data    = cbind(X, cluster)
return(list(X_test=X, t_test = t, lambda_test = lambda,
cluster = cluster ,
rand_effects_test = rand_effects, test_data=test_data))
}
test.data      = test()
test_data      = test.data$test_data
X_test         = test.data$X_test
lambda_test    = test.data$lambda_test
rand_effects_test = test.data$rand_effects
cluster_test   = test.data$cluster #cluster ID for each subject
t_test         = test.data$t_test
#### End of simulating training and test data ================================
#################################################################################
# =========================================================================================
###############==== Fit "SBART FOR CLUSTERED, INTERVAL CENSORED DATA"
# ====================================== ====================##############################
train_data=data.frame(train_data)
num_iter       = 100
pred_iter_start= 98
pred_iter_stop = num_iter
q              = array(NA, n)
m              = array(NA, n)
m_star         = array(NA,n)
q_star         = array(NA,n)
t              = array(NA,n)
status         = array(NA, n)
status[which(is.na(right))] = 0 #right censored obs
status[which(left==right)]  = 1 #exact observations
status[which(left<right)]   = 2 #interval-censored obs
no_exact                    = length(which(status == 1))
no_interval                 = length(which(status == 2))
shape_prior_w             = 20
rate_prior_w              = shape_prior_w
shape_post_w              = array(NA, num_cluster)
rate_post_w               = array(NA, num_cluster)
#shape_prior        = fitdistr(t_hyper, "gamma", lower=c(0,0))$estimate[1]
#rate_prior         = fitdistr(t_hyper, "gamma", lower=c(0,0))$estimate[2]
# Initialize MCMC output --------------------------------------------------
baseline_hazard_parameter = array(0,num_iter)
grid                      = seq(0.1,1,length=10)
surv                      = array(NA, dim=c(pred_iter_stop-pred_iter_start+1, n, length(grid)))
random_effect_parameter   = array(NA, num_iter)
theta                     = rgamma(num_cluster, shape = shape_prior_w, rate = rate_prior_w)
loglik_shape_prior_w = function( shape_prior_w){
logl = sum(dgamma(theta, shape = shape_prior_w, rate = shape_prior_w, log = T))
return(logl)
}
# Initialize model --------------------------------------------------------
omega       = 1/(mean(left+right)/2)
shape_prior = 1
rate_prior  = 1/omega
hypers      = Hypers(cbind((left+right)/2, X), (left+right)/2, sigma_hat = 1, num_tree = 50)
opts        = Opts(update_sigma = TRUE, update_s = FALSE, update_alpha = FALSE, update_sigma_mu = FALSE)
my_forest   = MakeForest(hypers, opts)
hazard      = function(s){2* omega*pnorm(my_forest$do_predict( cbind(s,cov) ))}
q=array(NA,n)
m=array(NA,n)
t = array(NA, n)
start.time = Sys.time()
for(iter in 1:num_iter)
{
z=NULL
X_i = NULL
X_store=NULL
#theta_store=NULL
#theta_i = NULL
time_points=NULL
g=NULL
#cluster_ID_i = NULL
#cluster_ID_long = NULL
for(i in 1:n)
{
g=NULL
if (status[i]==1 || status[i]==2){ #begin imputation for left and interval censored observations
if(status[i]==1)
{t[i] = left[i]} else if(status[i]==2){
m_star[i]=0
while(m_star[i] == 0){
q_star[i]   = extraDistr::rtpois(1, 2*omega*theta[cluster[i]]*(right[i] - left[i]), 1, Inf)
c_star      = runif(q_star[i], 2*omega*theta[cluster[i]]*left[i], 2*omega*theta[cluster[i]]*right[i])
a_star      = c_star/(2*omega*theta[cluster[i]])
astar_X_a   = cbind(a_star, matrix(rep(X[i,],length(a_star)), nrow=length(a_star),
ncol=p, byrow=T))
l_star      = my_forest$do_predict(astar_X_a)
u_star      = runif(q_star[i])
m_star[i]   = length(which(u_star <  pnorm(l_star)))
}
t[i]        = min(a_star[ c(which(u_star < pnorm(l_star))) ])
} #end of imputation
q[i]=rpois(1, 2*omega*theta[cluster[i]]*t[i])   #sampling number of events in interval (0, LAMBDA(t_i)=omega*t_i)
if (q[i]==0){m[i]=0} else{
c = runif(q[i], 0, 2*omega*theta[cluster[i]]*t[i])
a = c/(2*omega*theta[cluster[i]])
a_X_a = cbind(a, matrix(rep(X[i,],length(a)), nrow=length(a), ncol=p, byrow=T))
l = my_forest$do_predict(a_X_a)
u = runif(q[i])
g = a[which(u < 1 - pnorm(l) )]  #obtain rejected time points for subject i
m[i] = length(g)   #number of rejected time points for subject i
}
z_t = msm::rtnorm(1,mean = my_forest$do_predict(cbind(t[i], t(X[i,]))), sd=1, lower=0, upper=Inf)
if (m[i]>0)
{
z_g=array(0, m[i])
for (j in 1: m[i])
{
z_g[j] = msm::rtnorm(1,my_forest$do_predict(cbind(g[j], t(X[i,]))), 1, lower=-Inf, upper=0)
#cat(paste0("mean is", my_forest$predict(cbind(g[j], t(X[i,]))), "\t"))
}
z_store =c(z_g,z_t)
} else{
z_store=z_t
}
z=c(z, z_store)  #latent variable for subject i
#covariate vector for subject i repeated m[i]+1 times
X_i = matrix(rep(X[i,],m[i]+1), nrow=m[i]+1, ncol=p, byrow=T)
X_store=rbind(X_store, X_i)
time_points =  c(time_points,g,t[i] )
#theta_i = rep(theta[cluster[i]], m[i]+1)
#theta_store = c(theta_store, theta_i)
} else if (status[i]==0){
t[i] = left[i]
q[i]=rpois(1, 2*omega*theta[cluster[i]]*t[i])   #sampling number of events in interval (0, LAMBDA(t_i)=2omega*t_i)
if (q[i]==0){m[i]=0} else{
c = runif(q[i], 0, 2*omega*theta[cluster[i]]*t[i])
a = c/(2*omega*theta[cluster[i]])
a_X_a = cbind(a, matrix(rep(X[i,],length(a)), nrow=length(a), ncol=p, byrow=T))
l = my_forest$do_predict(a_X_a)
u = runif(q[i])
g = a[which(u < 1- pnorm(l) )]  #obtain rejected time points for subject i
m[i] = length(g)   #number of rejected time points for subject i
}
if (m[i]>0)
{
z_g=array(0, m[i])
for (j in 1: m[i])
{
z_g[j] = msm::rtnorm(1,my_forest$do_predict(cbind(g[j], t(X[i,]))), 1, lower=-Inf, upper=0)
#cat(paste0("mean is", my_forest$predict(cbind(g[j], t(X[i,]))), "\t"))
}
z_store =z_g
X_i = matrix(rep(X[i,],m[i]), nrow=m[i], ncol=p, byrow=T)
} else{
z_store=NULL
X_i = NULL
}
z=c(z, z_store)  #latent variable for subject i
#covariate vector for subject i repeated m[i]+1 times
#X_i = matrix(rep(X[i,],m[i]+1), nrow=m[i]+1, ncol=p, byrow=T)
X_store=rbind(X_store, X_i)
time_points =  c(time_points,g )
#theta_i = rep(theta[cluster[i]], m[i])
#theta_store = c(theta_store, theta_i)
}
#cluster_ID_i = rep(cluster[i], length(z_store))
#cluster_ID_long = c(cluster_ID_long, cluster_ID_i)
#cluster_ID_i    = NULL
}##########end of i-loop
#updates parameter of the baseline hazard function
sum_t = array(NA, num_cluster)
for(cl in 1:num_cluster){
sum_t[cl] = sum(t[cluster == cl])
}
omega = rgamma(1, shape = (sum(m)+ no_exact + no_interval + shape_prior), rate=(2*theta%*%sum_t+rate_prior) )
baseline_hazard_parameter[iter]=omega
#update cluster-specific random effects theta by sampling from its posterior distribution
mu_hat = my_forest$do_gibbs(cbind(time_points, X_store),z,cbind(time_points, X_store),1 )
#y = z - mu_hat
for(cl in 1:num_cluster){
shape_post_w[cl] = sum(m[cluster==cl]) + length(which(cluster==cl & status!= 0)) + shape_prior_w
rate_post_w[cl]  = 2*omega*sum_t[cl] + rate_prior_w
theta[cl]        = rgamma(1,shape= shape_post_w[cl], rate=rate_post_w[cl])
}
shape_prior_w=( diversitree::mcmc(lik=loglik_shape_prior_w,
nsteps=1, w=1, x.init=c(shape_prior_w),
prior = function(shape_prior_w)
dgamma(shape_prior_w, shape = 4,
rate=0.01, log = TRUE), lower=0, upper=Inf) )$pars
rate_prior_w = shape_prior_w
random_effect_parameter[iter] = shape_prior_w
cat(paste0("\rFinishing iteration ", iter, "\t\t\t"))
if(iter >= pred_iter_start && iter<= pred_iter_stop){
#w        = rgamma(1, shape = shape_prior_w, rate = rate_prior_w)
for(j in 1:nrow(X_test)){
XT_grid = cbind(grid, matrix(rep(X_test[j,], length(grid)), nrow = length(grid), byrow = TRUE))
integrand= pnorm(as.numeric(my_forest$do_predict(XT_grid)))
integral = cumsum(integrand) * (max(grid)-min(grid))/length(grid)
integral  = c(0, integral[-length(grid)])
surv[iter-pred_iter_start+1,j,] = (1 + (2*omega*integral/shape_prior_w))^(-shape_prior_w)
cat(paste0("\rFinishing iter ",iter,"predicted subject no. ", j, "\t\t\t"))
}
}
}
stop.time = Sys.time()
cat(paste0("\rFinishing replicate ", rep, "\t\t\t"))
surv_test        = apply(surv[1:dim(surv)[1],,], c(2,3), mean)
# Plotting true survival functions --------------------------------------------
grid=seq(0.1, max(train_data$right), length=10)
surv_test_true  = matrix(NA, nrow = n, ncol = length(grid))
#lambda_test          = lambda
#rand_effects_test    = rand_effects
#cluster_test         = train_data$id
for(i in 1:n){
surv_test_true[i,] = sapply(grid, function(x) 1-pgamma(x, shape = lambda_test[i]+rand_effects_test[cluster_test[i]], rate=6))
}
rmse[rep]            = sqrt(mean((surv_test - surv_test_true)^2))
}
rmse
rep
num_rep = 100
rmse    = array(NA, num_rep)
for(rep in 1:num_rep){
set.seed(rep)
sim_data = function(n=100, p=5, k=10, cl_size = n/k){
rand_effects = runif(k,0,0.2)
cluster      = c(rep(1:k, cl_size))
X            = matrix(runif(n*p), nrow = n, byrow = TRUE)
lambda       = 10*sin(pi*X[,1]*X[,2]) + 20*(X[,3]-0.5)**2+ 10*X[,4] + 5*X[,5]
t            = array(NA, n)
for(i in 1:n){
t[i] = rgamma(1, shape= lambda[i]+rand_effects[cluster[i]], rate=6)
}
# Obtain intervals ===================================
M            = sapply(t, function(x) rpois(1,x))
left         = array(NA, n)
right        = array(NA, n)
for(i in 1:n){
left[i]    = ifelse(M[i]>0, t[i]*(runif(1))^(1/M[i]), t[i])
right[i]   = t[i] + rexp(1)
}
train_data  = data.frame(cbind(left, right, X, cluster, event=array(1,n)))
colnames(train_data) = c("left", "right", "x1", "x2", "x3", "x4", "x5", "id", "event")
return(list(X=X, t = t, left = left, right = right, cluster = cluster , rand_effects = rand_effects,
k=k, lambda=lambda, train_data = train_data, p=p))
}
my_data        = sim_data()
train_data     = my_data$train_data
p              = my_data$p
n              = nrow(train_data)
num_cluster    = my_data$k             #no of clusters
rand_effects   = my_data$rand_effects
lambda         = my_data$lambda
left           = train_data$left
right          = train_data$right
max            = max(left,right)
left           = left/max
right          = right/max
X              = cbind(train_data$x1, train_data$x2, train_data$x3, train_data$x4, train_data$x5)
cluster        = train_data$id
# Test dataset =================================================================================
test = function(n=100, p=5, k=10, cl_size = n/k){
rand_effects = runif(k,0,0.2)
cluster      = c(rep(1:k, cl_size))
X            = matrix(runif(n*p), nrow = n, byrow = TRUE)
lambda       = 10*sin(pi*X[,1]*X[,2]) + 20*(X[,3]-0.5)**2 + 10*X[,4] + 5*X[,5]
t            = array(NA, n)
for(i in 1:n){
t[i] = rgamma(1, shape=lambda[i]+rand_effects[cluster[i]], rate=6)
}
test_data    = cbind(X, cluster)
return(list(X_test=X, t_test = t, lambda_test = lambda,
cluster = cluster ,
rand_effects_test = rand_effects, test_data=test_data))
}
test.data      = test()
test_data      = test.data$test_data
X_test         = test.data$X_test
lambda_test    = test.data$lambda_test
rand_effects_test = test.data$rand_effects
cluster_test   = test.data$cluster #cluster ID for each subject
t_test         = test.data$t_test
#### End of simulating training and test data ================================
#################################################################################
# =========================================================================================
###############==== Fit "SBART FOR CLUSTERED, INTERVAL CENSORED DATA"
# ====================================== ====================##############################
train_data=data.frame(train_data)
num_iter       = 100
pred_iter_start= 98
pred_iter_stop = num_iter
q              = array(NA, n)
m              = array(NA, n)
m_star         = array(NA,n)
q_star         = array(NA,n)
t              = array(NA,n)
status         = array(NA, n)
status[which(is.na(right))] = 0 #right censored obs
status[which(left==right)]  = 1 #exact observations
status[which(left<right)]   = 2 #interval-censored obs
no_exact                    = length(which(status == 1))
no_interval                 = length(which(status == 2))
shape_prior_w             = 20
rate_prior_w              = shape_prior_w
shape_post_w              = array(NA, num_cluster)
rate_post_w               = array(NA, num_cluster)
#shape_prior        = fitdistr(t_hyper, "gamma", lower=c(0,0))$estimate[1]
#rate_prior         = fitdistr(t_hyper, "gamma", lower=c(0,0))$estimate[2]
# Initialize MCMC output --------------------------------------------------
baseline_hazard_parameter = array(0,num_iter)
grid                      = seq(0.1,1,length=10)
surv                      = array(NA, dim=c(pred_iter_stop-pred_iter_start+1, n, length(grid)))
random_effect_parameter   = array(NA, num_iter)
theta                     = rgamma(num_cluster, shape = shape_prior_w, rate = rate_prior_w)
loglik_shape_prior_w = function( shape_prior_w){
logl = sum(dgamma(theta, shape = shape_prior_w, rate = shape_prior_w, log = T))
return(logl)
}
# Initialize model --------------------------------------------------------
omega       = 1/(mean(left+right)/2)
shape_prior = 1
rate_prior  = 1/omega
hypers      = Hypers(cbind((left+right)/2, X), (left+right)/2, sigma_hat = 1, num_tree = 50)
opts        = Opts(update_sigma = TRUE, update_s = FALSE, update_alpha = FALSE, update_sigma_mu = FALSE)
my_forest   = MakeForest(hypers, opts)
hazard      = function(s){2* omega*pnorm(my_forest$do_predict( cbind(s,cov) ))}
q=array(NA,n)
m=array(NA,n)
t = array(NA, n)
start.time = Sys.time()
for(iter in 1:num_iter)
{
z=NULL
X_i = NULL
X_store=NULL
#theta_store=NULL
#theta_i = NULL
time_points=NULL
g=NULL
#cluster_ID_i = NULL
#cluster_ID_long = NULL
for(i in 1:n)
{
g=NULL
if (status[i]==1 || status[i]==2){ #begin imputation for left and interval censored observations
if(status[i]==1)
{t[i] = left[i]} else if(status[i]==2){
m_star[i]=0
while(m_star[i] == 0){
q_star[i]   = extraDistr::rtpois(1, 2*omega*theta[cluster[i]]*(right[i] - left[i]), 1, Inf)
c_star      = runif(q_star[i], 2*omega*theta[cluster[i]]*left[i], 2*omega*theta[cluster[i]]*right[i])
a_star      = c_star/(2*omega*theta[cluster[i]])
astar_X_a   = cbind(a_star, matrix(rep(X[i,],length(a_star)), nrow=length(a_star),
ncol=p, byrow=T))
l_star      = my_forest$do_predict(astar_X_a)
u_star      = runif(q_star[i])
m_star[i]   = length(which(u_star <  pnorm(l_star)))
}
t[i]        = min(a_star[ c(which(u_star < pnorm(l_star))) ])
} #end of imputation
q[i]=rpois(1, 2*omega*theta[cluster[i]]*t[i])   #sampling number of events in interval (0, LAMBDA(t_i)=omega*t_i)
if (q[i]==0){m[i]=0} else{
c = runif(q[i], 0, 2*omega*theta[cluster[i]]*t[i])
a = c/(2*omega*theta[cluster[i]])
a_X_a = cbind(a, matrix(rep(X[i,],length(a)), nrow=length(a), ncol=p, byrow=T))
l = my_forest$do_predict(a_X_a)
u = runif(q[i])
g = a[which(u < 1 - pnorm(l) )]  #obtain rejected time points for subject i
m[i] = length(g)   #number of rejected time points for subject i
}
z_t = msm::rtnorm(1,mean = my_forest$do_predict(cbind(t[i], t(X[i,]))), sd=1, lower=0, upper=Inf)
if (m[i]>0)
{
z_g=array(0, m[i])
for (j in 1: m[i])
{
z_g[j] = msm::rtnorm(1,my_forest$do_predict(cbind(g[j], t(X[i,]))), 1, lower=-Inf, upper=0)
#cat(paste0("mean is", my_forest$predict(cbind(g[j], t(X[i,]))), "\t"))
}
z_store =c(z_g,z_t)
} else{
z_store=z_t
}
z=c(z, z_store)  #latent variable for subject i
#covariate vector for subject i repeated m[i]+1 times
X_i = matrix(rep(X[i,],m[i]+1), nrow=m[i]+1, ncol=p, byrow=T)
X_store=rbind(X_store, X_i)
time_points =  c(time_points,g,t[i] )
#theta_i = rep(theta[cluster[i]], m[i]+1)
#theta_store = c(theta_store, theta_i)
} else if (status[i]==0){
t[i] = left[i]
q[i]=rpois(1, 2*omega*theta[cluster[i]]*t[i])   #sampling number of events in interval (0, LAMBDA(t_i)=2omega*t_i)
if (q[i]==0){m[i]=0} else{
c = runif(q[i], 0, 2*omega*theta[cluster[i]]*t[i])
a = c/(2*omega*theta[cluster[i]])
a_X_a = cbind(a, matrix(rep(X[i,],length(a)), nrow=length(a), ncol=p, byrow=T))
l = my_forest$do_predict(a_X_a)
u = runif(q[i])
g = a[which(u < 1- pnorm(l) )]  #obtain rejected time points for subject i
m[i] = length(g)   #number of rejected time points for subject i
}
if (m[i]>0)
{
z_g=array(0, m[i])
for (j in 1: m[i])
{
z_g[j] = msm::rtnorm(1,my_forest$do_predict(cbind(g[j], t(X[i,]))), 1, lower=-Inf, upper=0)
#cat(paste0("mean is", my_forest$predict(cbind(g[j], t(X[i,]))), "\t"))
}
z_store =z_g
X_i = matrix(rep(X[i,],m[i]), nrow=m[i], ncol=p, byrow=T)
} else{
z_store=NULL
X_i = NULL
}
z=c(z, z_store)  #latent variable for subject i
#covariate vector for subject i repeated m[i]+1 times
#X_i = matrix(rep(X[i,],m[i]+1), nrow=m[i]+1, ncol=p, byrow=T)
X_store=rbind(X_store, X_i)
time_points =  c(time_points,g )
#theta_i = rep(theta[cluster[i]], m[i])
#theta_store = c(theta_store, theta_i)
}
#cluster_ID_i = rep(cluster[i], length(z_store))
#cluster_ID_long = c(cluster_ID_long, cluster_ID_i)
#cluster_ID_i    = NULL
}##########end of i-loop
#updates parameter of the baseline hazard function
sum_t = array(NA, num_cluster)
for(cl in 1:num_cluster){
sum_t[cl] = sum(t[cluster == cl])
}
omega = rgamma(1, shape = (sum(m)+ no_exact + no_interval + shape_prior), rate=(2*theta%*%sum_t+rate_prior) )
baseline_hazard_parameter[iter]=omega
#update cluster-specific random effects theta by sampling from its posterior distribution
mu_hat = my_forest$do_gibbs(cbind(time_points, X_store),z,cbind(time_points, X_store),1 )
#y = z - mu_hat
for(cl in 1:num_cluster){
shape_post_w[cl] = sum(m[cluster==cl]) + length(which(cluster==cl & status!= 0)) + shape_prior_w
rate_post_w[cl]  = 2*omega*sum_t[cl] + rate_prior_w
theta[cl]        = rgamma(1,shape= shape_post_w[cl], rate=rate_post_w[cl])
}
shape_prior_w=( diversitree::mcmc(lik=loglik_shape_prior_w,
nsteps=1, w=1, x.init=c(shape_prior_w),
prior = function(shape_prior_w)
dgamma(shape_prior_w, shape = 4,
rate=0.01, log = TRUE), lower=0, upper=Inf) )$pars
rate_prior_w = shape_prior_w
random_effect_parameter[iter] = shape_prior_w
cat(paste0("\rFinishing iteration ", iter, "\t\t\t"))
if(iter >= pred_iter_start && iter<= pred_iter_stop){
#w        = rgamma(1, shape = shape_prior_w, rate = rate_prior_w)
for(j in 1:nrow(X_test)){
XT_grid = cbind(grid, matrix(rep(X_test[j,], length(grid)), nrow = length(grid), byrow = TRUE))
integrand= pnorm(as.numeric(my_forest$do_predict(XT_grid)))
integral = cumsum(integrand) * (max(grid)-min(grid))/length(grid)
integral  = c(0, integral[-length(grid)])
surv[iter-pred_iter_start+1,j,] = (1 + (2*omega*integral/shape_prior_w))^(-shape_prior_w)
cat(paste0("\rFinishing iter ",iter,"predicted subject no. ", j, "\t\t\t"))
}
}
}
stop.time = Sys.time()
cat(paste0("\rFinishing replicate ", rep, "\t\t\t"))
surv_test        = apply(surv[1:dim(surv)[1],,], c(2,3), mean)
# Plotting true survival functions --------------------------------------------
grid=seq(0.1, max(train_data$right), length=10)
surv_test_true  = matrix(NA, nrow = n, ncol = length(grid))
#lambda_test          = lambda
#rand_effects_test    = rand_effects
#cluster_test         = train_data$id
for(i in 1:n){
surv_test_true[i,] = sapply(grid, function(x) 1-pgamma(x, shape = lambda_test[i]+rand_effects_test[cluster_test[i]], rate=6))
}
rmse[rep]            = sqrt(mean((surv_test - surv_test_true)^2))
}
rmse
mean(rmse)
options(java.parameters = "-Xmx5g")
library(Rcpp)
library(RcppArmadillo)
library(devtools)
library(BART)
library(MCMCglmm)
library(truncnorm)
library(hmclearn)
library(rstan)
rstan_options(auto_write = TRUE)
library(rstan)
